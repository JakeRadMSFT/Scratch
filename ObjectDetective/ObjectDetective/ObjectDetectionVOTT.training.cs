// See https://aka.ms/new-console-template for more information
using Microsoft.ML;
using Microsoft.ML.Data;
using Microsoft.ML.TorchSharp;
using Microsoft.ML.TorchSharp.AutoFormerV2;
using System.Text.Json;
using System.Text.Json.Nodes;
using Tensorflow;
// This file was auto-generated by ML.NET Model Builder.


namespace ObjectDetective
{
    public partial class ObjectDetectionVOTT
    {

        public const string RetrainFilePath = @"C:\dev\datasets\OD-cats\OD-cats\vott-json-export\cats-export.json";


        /// <summary>
        /// Train a new model with the provided dataset.
        /// </summary>
        /// <param name="outputModelPath">File path for saving the model. Should be similar to "C:\YourPath\ModelName.mlnet"</param>
        /// <param name="inputDataFilePath">Path to the data file for training.</param>
        /// <param name="separatorChar">Separator character for delimited training file.</param>
        /// <param name="hasHeader">Boolean if training file has a header.</param>
        public static void Train(string outputModelPath, MLContext? mlContext = null, string inputDataFilePath = RetrainFilePath)
        {
            mlContext ??= new MLContext();

            var data = LoadIDataViewFromVOTTFile(mlContext, inputDataFilePath);
            var model = RetrainModel(mlContext, data);
            SaveModel(mlContext, model, data, outputModelPath);
        }

        public static IEnumerable<ModelInput> LoadFromVott(string inputDataFilePath)
        {

            JsonNode jsonNode;
            using (StreamReader r = new StreamReader(inputDataFilePath))
            {
                string json = r.ReadToEnd();
                jsonNode = JsonSerializer.Deserialize<JsonNode>(json);
            }

            var imageData = new List<ModelInput>();
            foreach (KeyValuePair<string, JsonNode> asset in jsonNode["assets"].AsObject())
            {
                var labelList = new List<string>();
                var boxList = new List<float>();
                foreach (var region in asset.Value["regions"].AsArray())
                {
                    foreach (var tag in region["tags"].AsArray())
                    {
                        labelList.Add(tag.GetValue<string>());

                        var boundingBox = region["boundingBox"];

                        var left = boundingBox["left"].GetValue<float>();
                        var top = boundingBox["top"].GetValue<float>();
                        var width = boundingBox["width"].GetValue<float>();
                        var height = boundingBox["height"].GetValue<float>();


                        boxList.Add(left);
                        boxList.Add(top);
                        boxList.Add(left + width);
                        boxList.Add(top + height);
                    }
                }

                var modelInput = new ModelInput()
                {
                    ImagePath = asset.Value["asset"]["path"].GetValue<string>().Replace("file:",""),
                    Labels = labelList.ToArray(),
                    Box = boxList.ToArray(),
                };

                imageData.Add(modelInput);
            }

            
            return imageData;
        }


        /// <summary>
        /// Load an IDataView from a file path.
        /// </summary>
        /// <param name="mlContext">The common context for all ML.NET operations.</param>
        /// <param name="inputDataFilePath">Path to the data file for training.</param>
        /// <param name="separatorChar">Separator character for delimited training file.</param>
        /// <param name="hasHeader">Boolean if training file has a header.</param>
        /// <returns>IDataView with loaded training data.</returns>
        public static IDataView LoadIDataViewFromVOTTFile(MLContext mlContext, string inputDataFilePath)
        {
            var data = mlContext.Data.LoadFromEnumerable(LoadFromVott(inputDataFilePath));

            return data;
        }


        /// <summary>
        /// Save a model at the specified path.
        /// </summary>
        /// <param name="mlContext">The common context for all ML.NET operations.</param>
        /// <param name="model">Model to save.</param>
        /// <param name="data">IDataView used to train the model.</param>
        /// <param name="modelSavePath">File path for saving the model. Should be similar to "C:\YourPath\ModelName.mlnet.</param>
        public static void SaveModel(MLContext mlContext, ITransformer model, IDataView data, string modelSavePath)
        {
            // Pull the data schema from the IDataView used for training the model
            DataViewSchema dataViewSchema = data.Schema;

            using (var fs = File.Create(modelSavePath))
            {
                mlContext.Model.Save(model, dataViewSchema, fs);
            }
        }


        /// <summary>
        /// Retrains model using the pipeline generated as part of the training process.
        /// </summary>
        /// <param name="mlContext"></param>
        /// <param name="trainData"></param>
        /// <returns></returns>
        public static ITransformer RetrainModel(MLContext mlContext, IDataView trainData)
        {
            var pipeline = BuildPipeline(mlContext);
            var model = pipeline.Fit(trainData);

            return model;
        }


        /// <summary>
        /// build the pipeline that is used from model builder. Use this function to retrain model.
        /// </summary>
        /// <param name="mlContext"></param>
        /// <returns></returns>
        public static IEstimator<ITransformer> BuildPipeline(MLContext mlContext)
        {
            var options = new ObjectDetectionTrainer.Options()
            {
                LabelColumnName = "Labels",
                ImageColumnName = "Image",
                BoundingBoxColumnName = "Box",
                PredictedLabelColumnName = "PredictedLabel",
                ScoreColumnName = "Score",
                ScoreThreshold = 0.1,
                MaxEpoch = 5,
            };

            var chain = new EstimatorChain<ITransformer>();

            var pipeline = mlContext.Transforms.Conversion.MapValueToKey("Labels")
                .Append(mlContext.Transforms.LoadImages("Image", "", "ImagePath"))
                .Append(mlContext.Transforms.ResizeImages("Image", 400, 300))
                .Append(mlContext.MulticlassClassification.Trainers.ObjectDetection(options))
                .Append(mlContext.Transforms.Conversion.MapKeyToValue("PredictedLabel"));
            return pipeline;
        }
    }
}
